# Time-series
This project implements an advanced deep learning pipeline for probabilistic time series forecasting using LSTM or Temporal Convolutional Networks (TCN).
The goal is not only accurate point forecasting but also robust uncertainty quantification, enabling data-driven decision-making under uncertainty.

The model outputs:

Point forecast (mean)

Aleatoric uncertainty (data noise)

Epistemic uncertainty (model uncertainty) via Monte Carlo Dropout

Combined prediction intervals (80% and 95%)

The project includes:

Synthetic real-worldâ€“like dataset generation

Neural network-based probabilistic forecasting

Evaluation of forecast accuracy and uncertainty calibration

Visualization of predictions with uncertainty bands

ğŸ“Œ Project Highlights

âœ” Synthetic daily dataset (3 years) with trend, seasonalities, and heteroscedastic noise
âœ” Feature engineering (cyclic time features, lag windows)
âœ” LSTM model producing mean + log-variance trained via Gaussian Negative Log-Likelihood
âœ” MC Dropout for uncertainty estimation
âœ” Forecast metrics: RMSE, MAE
âœ” Probabilistic metrics: Coverage Probability, Mean Interval Width
âœ” Visualization of 80% & 95% Prediction Intervals
âœ” Fully documented, PEP 8â€“compliant, production-ready code

ğŸ“‚ File Structure
project/
â”‚
â”œâ”€â”€ probabilistic_lstm_forecast.py   # Main runnable pipeline
â”œâ”€â”€ ts_forecast_outputs/             # Generated metrics + plots
â”‚   â”œâ”€â”€ metrics.csv
â”‚   â”œâ”€â”€ forecast_plot_*.png
â”‚
â””â”€â”€ README.md                        # This file

ğŸ“Š Dataset Description

The dataset is synthetically generated to emulate a real-world time series with:

Linear trend

Yearly seasonality

Weekly seasonality

Heteroscedastic noise (time-varying variance)

Random outliers

This ensures a challenging forecasting task suitable for evaluating uncertainty-aware models.

ğŸ§  Model Architecture

The forecasting model is an LSTM-based probabilistic neural network:

Inputs

30-day lag window

Cyclic features:

sin_doy, cos_doy (day-of-year)

sin_dow, cos_dow (day-of-week)

Outputs

Î¼ â†’ mean forecast

log(ÏƒÂ²) â†’ predicted variance

Loss

Gaussian Negative Log Likelihood (NLL)

Uncertainty Estimation

Aleatoric uncertainty â†’ learned directly from log_var

Epistemic uncertainty â†’ Monte Carlo Dropout inference

Total predictive variance = aleatoric + epistemic

ğŸ“ˆ Evaluation Metrics
Point Forecast Metrics
Metric	Description
RMSE	Root Mean Squared Error
MAE	Mean Absolute Error
Uncertainty / Probabilistic Metrics
Metric	Meaning
Coverage_80	Fraction of true values inside 80% PI
Mean_Width_80	Average width of 80% PI
Coverage_95	Calibration accuracy of 95% PI
Mean_Width_95	Sharpness vs uncertainty trade-off
ğŸ“¦ Requirements

Install required libraries:

pip install numpy pandas scikit-learn matplotlib tensorflow scipy


To run CPU-only TensorFlow:

pip install tensorflow-cpu

ğŸš€ How to Run
1. Clone the repository
git clone <your-repo-url>
cd project/

2. Run the script
python probabilistic_lstm_forecast.py

3. View Outputs

Generated files will be saved in:

ts_forecast_outputs/


Includes:

metrics.csv â†’ evaluation metrics

forecast_plot_*.png â†’ forecast vs actual with 80/95% intervals

ğŸ“Š Example Output (when you run the script)
rmse: 0.874321
mae: 0.623145
coverage_80: 0.79
coverage_95: 0.95
mean_width_80: 1.20
mean_width_95: 2.45


(Values vary depending on training)

ğŸ§ª Hyperparameter Tuning

Recommended grid options:

LSTM units: 32, 64, 128

Dropout rate: 0.1â€“0.3

Lookback window: 14, 30, 60

Learning rate: 1e-3, 5e-4

Optimizer: Adam

Time-series cross-validation via rolling window is advised.

ğŸ“˜ Future Work

ğŸ”¹ Add TCN-based probabilistic forecaster
ğŸ”¹ Implement quantile regression using Pinball Loss
ğŸ”¹ Add multistep (H>1) forecasting support
ğŸ”¹ Compare MC Dropout vs Deep Ensembles
ğŸ”¹ Extend synthetic dataset to include:

regime shifts

structural breaks

missing data patterns

ğŸ¤ Contributing

Pull requests and improvements are welcome.
Follow PEP 8 and maintain docstring documentation for all functions and modules.
